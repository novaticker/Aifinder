# background_news_updater.py
import requests, json, os, re, random
from bs4 import BeautifulSoup
from datetime import datetime
import pytz

NEWS_FILE = "positive_news.json"
KST = pytz.timezone("Asia/Seoul")

def true_ai_summarize(text):
    text_lower = text.lower()
    symbol_match = re.search(r"\(([A-Z]+)\)", text)
    symbol = symbol_match.group(1) if symbol_match else ""
    company = symbol if symbol else "í•´ë‹¹ ê¸°ì—…"

    positive_adverbs = ["ê¸ì •ì ì¸", "ê³ ë¬´ì ì¸", "í¬ë§ì ì¸", "ì£¼ëª©í•  ë§Œí•œ", "í™œë°œí•œ"]
    market_reactions = [
        "ì‹œìž¥ ë°˜ì‘ì„ ì´ëŒ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.",
        "íˆ¬ìž ì‹¬ë¦¬ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.",
        "ì£¼ê°€ ë³€ë™ì— ì¤‘ìš”í•œ ìš”ì†Œë¡œ ìž‘ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.",
        "í–¥í›„ ì„±ìž¥ ê¸°ëŒ€ê°ì„ í‚¤ìš°ê³  ìžˆìŠµë‹ˆë‹¤.",
        "ì¤‘ìž¥ê¸° ê´€ì ì—ì„œ ì£¼ëª©ë°›ê³  ìžˆìŠµë‹ˆë‹¤."
    ]

    def combine(phrase):
        return f"{company}ëŠ” {phrase} {random.choice(market_reactions)}"

    if any(k in text_lower for k in ["fda", "approval", "phase", "clinical", "trial"]):
        return combine(f"{random.choice(positive_adverbs)} ìž„ìƒ ë˜ëŠ” ìŠ¹ì¸ ê´€ë ¨ ì†Œì‹ì„ ë°œí‘œí•˜ë©°")
    elif any(k in text_lower for k in ["merger", "acquisition", "buyout"]):
        return combine("ì¸ìˆ˜í•©ë³‘(M&A) ê´€ë ¨ ë°œí‘œë¥¼ í†µí•´")
    elif any(k in text_lower for k in ["investment", "funding", "raise", "partnership"]):
        amt = re.search(r"(\$[0-9,.]+[MB]?)", text)
        amount = amt.group(1) if amt else "ìžê¸ˆ"
        return combine(f"{amount} ê·œëª¨ì˜ íˆ¬ìž ë˜ëŠ” ì œíœ´ë¥¼ ì§„í–‰í•˜ë©°")
    elif any(k in text_lower for k in ["launch", "release", "expansion", "product", "platform"]):
        return combine("ì‹ ì œí’ˆ ë˜ëŠ” í”Œëž«í¼ í™•ìž¥ì„ ë°œí‘œí•˜ë©°")
    elif any(k in text_lower for k in ["earnings", "revenue", "record", "profit", "%", "financial"]):
        return combine("ìž¬ë¬´ ìˆ˜ì¹˜ ë˜ëŠ” ì‹¤ì  ë°œí‘œë¥¼ í†µí•´")
    elif any(k in text_lower for k in ["award", "event", "presentation", "expo"]):
        return combine("ê³µì‹ ë°œí‘œ ë˜ëŠ” ìˆ˜ìƒ ì†Œì‹ì„ ì „ë‹¬í•˜ë©°")
    elif any(k in text_lower for k in ["contract", "agreement", "deal", "signed"]):
        return combine("ê³„ì•½ ë˜ëŠ” í˜‘ì•½ ì²´ê²°ì„ ë°œí‘œí•˜ë©°")
    else:
        general = [
            "ì¤‘ìš”í•œ ê¸°ì—… í™œë™ì„ ë°œí‘œí•˜ë©°",
            "ìƒˆë¡œìš´ ì „ëžµì„ ì œì‹œí•˜ë©°",
            "ì‹œìž¥ê³¼ íˆ¬ìžìžë“¤ì—ê²Œ ì˜í–¥ì„ ì¤„ ìˆ˜ ìžˆëŠ” ì†Œì‹ì„ ë°œí‘œí•˜ë©°",
            "ë³€í™”ì˜ ì‹ í˜¸ë¡œ í•´ì„ë  ìˆ˜ ìžˆëŠ” ë‰´ìŠ¤ë¥¼ ì „ë‹¬í•˜ë©°"
        ]
        return combine(random.choice(general))

def clean_symbol(text):
    m = re.search(r"\(([A-Z]+)\)", text)
    return m.group(1) if m else ""

def fetch_toss_gainers():
    url = "https://tossinvest.com/screener"
    res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(res.text, "html.parser")
    gainers = []
    for tag in soup.select("div > strong"):
        symbol = tag.text.strip()
        if len(symbol) <= 5 and symbol.isupper():
            gainers.append({"symbol": symbol})
    return gainers

def fetch_news_from_prnews():
    url = "https://www.prnewswire.com/news-releases/news-releases-list/"
    res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(res.text, "html.parser")
    news_list = []

    for item in soup.select(".newsRelease"):
        title_tag = item.select_one(".newsTitle")
        if title_tag:
            title = title_tag.text.strip()
            link = "https://www.prnewswire.com" + title_tag.get("href")
            summary = true_ai_summarize(title)
            symbol = clean_symbol(title)
            now = datetime.now(KST)
            news_list.append({
                "title": title,
                "link": link,
                "summary": summary,
                "symbol": symbol,
                "time": now.strftime("%H:%M"),
                "timestamp": now.timestamp(),
                "date": now.strftime("%Y-%m-%d"),
                "source": "PRNewswire"
            })
    return news_list

def save_data(news, gainers):
    today = datetime.now(KST).strftime("%Y-%m-%d")
    if os.path.exists(NEWS_FILE):
        with open(NEWS_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
    else:
        data = {}
    data[today] = {
        "news": news,
        "gainers": gainers,
        "signals": []
    }
    with open(NEWS_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def main():
    print("ðŸ¤– ì§„ì§œ AI íƒìƒ‰ê¸° ìž‘ë™ ì¤‘...")
    gainers = fetch_toss_gainers()
    news = fetch_news_from_prnews()
    save_data(news, gainers)
    print("âœ… ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ")

def update_news():
    main()

if __name__ == "__main__":
    main()
