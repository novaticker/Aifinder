import requests
from bs4 import BeautifulSoup
from datetime import datetime
import pytz
import json
import re

KST = pytz.timezone("Asia/Seoul")
NEWS_FILE = "positive_news.json"

# ðŸ“Š í”„ìž¥ / ðŸ“ˆ ë³¸ìž¥ / ðŸŒ™ ì•±ìž¥ êµ¬ë¶„
def get_phase_now():
    now = datetime.now(KST).time()
    if now < datetime.strptime("22:30", "%H:%M").time():
        return "ðŸ“Š í”„ìž¥"
    elif now < datetime.strptime("05:00", "%H:%M").time():
        return "ðŸ“ˆ ë³¸ìž¥"
    else:
        return "ðŸŒ™ ì•±ìž¥"

# ê°€ì§œ AI ìš”ì•½ ìƒì„±ê¸°
def true_ai_summarize(title):
    text = title.lower()
    if any(k in text for k in ["fda", "approval", "clinical", "phase"]):
        return "ìž„ìƒ/ìŠ¹ì¸ ê´€ë ¨ ë°œí‘œë¡œ ê¸°ëŒ€ê° ìƒìŠ¹"
    if any(k in text for k in ["merger", "acquisition", "buyout"]):
        return "M&A ê´€ë ¨ ì†Œì‹ìœ¼ë¡œ íˆ¬ìžìž ê´€ì‹¬ ì§‘ì¤‘"
    if any(k in text for k in ["investment", "funding", "raises", "capital"]):
        return "íˆ¬ìžìœ ì¹˜ ë˜ëŠ” ìžê¸ˆ ì¡°ë‹¬ ë°œí‘œ"
    if any(k in text for k in ["launch", "expand", "partnership", "open"]):
        return "ì‹ ì œí’ˆ ì¶œì‹œ, í™•ìž¥ ë˜ëŠ” ì œíœ´ ë°œí‘œ"
    if any(k in text for k in ["record", "surge", "strong", "beat"]):
        return "ì‹¤ì  í˜¸ì¡° ë˜ëŠ” ì„±ìž¥ ê¸°ë¡ ë°œí‘œ"
    return "ê¸ì •ì ì¸ ê¸°ì—… ë°œí‘œë¡œ ì£¼ëª©"

# ì‹¬ë³¼ ì¶”ì¶œ (ëŒ€ë¬¸ìž ì—°ì†)
def extract_symbol(text):
    matches = re.findall(r"\b[A-Z]{2,5}\b", text)
    if matches:
        return matches[0]
    return ""

# PR Newswire í¬ë¡¤ë§
def fetch_news_from_prnews():
    url = "https://www.prnewswire.com/news-releases/news-releases-list/"
    res = requests.get(url, timeout=10)
    soup = BeautifulSoup(res.text, "html.parser")
    items = soup.select(".card")
    results = []
    for item in items:
        title_tag = item.select_one(".news-release .card-title")
        if not title_tag:
            continue
        title = title_tag.text.strip()
        link = "https://www.prnewswire.com" + title_tag.get("href", "")
        symbol = extract_symbol(title)
        summary = true_ai_summarize(title)
        time_str = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")
        source = "PRNewswire"
        results.append({
            "title": title,
            "summary": summary,
            "link": link,
            "symbol": symbol,
            "time": time_str,
            "timestamp": datetime.now(KST).timestamp(),
            "date": datetime.now(KST).strftime("%Y-%m-%d"),
            "source": source
        })
    return results

# TossInvest ê¸‰ë“± ì¢…ëª© ê°ì§€
def fetch_toss_gainers():
    try:
        url = "https://www.tossinvest.com/api/statics/today-top-rising-stocks"
        res = requests.get(url, timeout=10)
        data = res.json().get("data", [])
        phase = get_phase_now()
        gainers = []
        for item in data:
            symbol = item.get("symbol", "")
            change = item.get("changeRate", "")
            gainers.append({
                "symbol": symbol,
                "change": change,
                "phase": phase
            })
        return gainers
    except:
        return []

# ë°ì´í„° ì €ìž¥
def save_data(news_items, gainers):
    date = datetime.now(KST).strftime("%Y-%m-%d")
    if not news_items and not gainers:
        return

    if not os.path.exists(NEWS_FILE):
        data = {}
    else:
        with open(NEWS_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)

    if date not in data:
        data[date] = {"news": [], "gainers": []}

    # ë‰´ìŠ¤ ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ì¤€)
    existing_titles = {item["title"] for item in data[date]["news"]}
    new_news = [item for item in news_items if item["title"] not in existing_titles]
    data[date]["news"].extend(new_news)

    # ê¸‰ë“± ì¢…ëª© ìµœì‹ í™”
    data[date]["gainers"] = gainers

    with open(NEWS_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•  í•¨ìˆ˜
def update_news():
    news = fetch_news_from_prnews()
    gainers = fetch_toss_gainers()
    save_data(news, gainers)

# ìˆ˜ë™ ì‹¤í–‰ìš©
if __name__ == "__main__":
    update_news()
